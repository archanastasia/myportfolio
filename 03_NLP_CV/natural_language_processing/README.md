`Keras` `pandas` `Torch` 

# обработка токсичных комментаиев c BERT
Интернет магазин разрабатывает инструмент по поиску токсичных комментариев, которые будут отправляться на модерацию.
В нашем распоряжениинабор данных с разметкой о токсичности правок.
Необходимо создать модель которая будет отделять токсичные комментарии. Желаемое качество на метрике F1 не меньше 0.75.

Столбец text содержит текст комментария, а toxic — целевой признак.

В ходе проекта будут рассмотрены варианты обработки комментариев с помощью технологии Bert


# Выводы
Тексты прошли обработку через токенизацию, лемматизацию и очистку от лишних символов. Модель DistilBert дает хорошие результаты, но мощность личного компьютера не позволяет использовать этот алгоритм в полном объеме. Среди моделей наилучший результат показал LightGBM.

Для оценки качества использовалась метрика F1. На простой не модифицированной линейной регрессии Bert дает качество 0.62, вместо 0.69 на TF-IDF векторизации.

Модели после обучения дают результат метрики 0.61-0.75 на тестовой выборке. Лучший результат дала модель LightGBM.
